{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 5 biggest countries by population in 2017 are china, india, united states, indonesia, and brazil.\n"
     ]
    }
   ],
   "source": [
    "# conversion to lower case\n",
    "input_str = \"The 5 biggest countries by population in 2017 are China, India, United States, Indonesia, and Brazil.\"\n",
    "input_str = input_str.lower()\n",
    "print(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranadhir.ghosh\\AppData\\Roaming\\nltk_data\\corpora\\brown\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "print(nltk.corpus.brown.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello World.', \"It's good to see you.\", 'Thanks for buying this book.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('english.pickle')\n",
    "para = \"Hello World. It's good to see you. Thanks for buying this book.\"\n",
    "tokenizer.tokenize(para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr. James told me Dr. Brown is not available today.', 'I will try tomorrow.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('english.pickle')\n",
    "text = \"Mr. James told me Dr. Brown is not available today. I will try tomorrow.\"\n",
    "\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Mr. James told me Dr. Brown is not available today.\"),\n",
       " Sentence(\"I will try tomorrow.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "text = \"Mr. James told me Dr. Brown is not available today. I will try tomorrow.\"\n",
    "\n",
    "s = TextBlob(text)\n",
    "s.sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK', 'leading', 'platform', 'building', 'Python', 'programs', 'work', 'human', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "input_str = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(input_str)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone.', 'Welcome to NLP online classroom.', 'NLP is fun']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"Hello everyone. Welcome to NLP online classroom. NLP is fun\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello everyone.', 'Welcome to NLP online classroom.', 'NLP is fun']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola amigo.', 'Estoy bien.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "\n",
    "spanish_text = \"Hola amigo. Estoy bien.\"\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')\n",
    "tokenizer.tokenize(spanish_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White guy: So, do you have any plans for this evening?\n",
      "Asian girl: Yeah, being angry!\n",
      "White guy: Oh, that sounds good.\n",
      "\n",
      "Guy #1: So this Jack guy is basically the luckiest man in the world.\n",
      "Guy #2: Why, because he's survived like 5 attempts on his life and it's not even noon?\n",
      "Guy #1: No; he could totally nail those two chicks.\n",
      "\n",
      "Dad: Could you tell me where the auditorium is?\n",
      "Security guy: It's on t\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import webtext\n",
    "text = webtext.raw('overheard.txt')\n",
    "print (text[0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = PunktSentenceTokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White guy: So, do you have any plans for this evening?\n"
     ]
    }
   ],
   "source": [
    "sents1 = sent_tokenizer.tokenize(text)\n",
    "print(sents1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White guy: So, do you have any plans for this evening?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sents2 = sent_tokenize(text)\n",
    "print(sents2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girl: But you already have a Big Mac...\n"
     ]
    }
   ],
   "source": [
    "print(sents1[678])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girl: But you already have a Big Mac...\n",
      "Hobo: Oh, this is all theatrical.\n"
     ]
    }
   ],
   "source": [
    "print(sents2[678])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My friend holds a Msc.', 'in Computer science']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sentence = \"My friend holds a Msc. in Computer science\"\n",
    "print (sent_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_LazyCorpusLoader__args', '_LazyCorpusLoader__kwargs', '_LazyCorpusLoader__load', '_LazyCorpusLoader__name', '_LazyCorpusLoader__reader_cls', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_unload', 'subdir', 'unicode_repr']\n",
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
      "11793318\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    " \n",
    "print (dir(gutenberg))\n",
    "print (gutenberg.fileids())\n",
    " \n",
    "text = \"\"\n",
    "for file_id in gutenberg.fileids():\n",
    "    text += gutenberg.raw(file_id)\n",
    " \n",
    "print (len(text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danc\n",
      "work\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"dancing\",\"Working\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unhappi\n",
      "imprecis\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "example_words = [\"unhappy\",\"imprecise\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unhappy\n",
      "imprec\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "example_words = [\"unhappy\",\"imprecise\"]\n",
    "for w in example_words:\n",
    "    print(lancaster_stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "dant\n",
      "work\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\",\"dancing\",\"Working\"]\n",
    "for w in example_words:\n",
    "    print(lancaster_stemmer.stem(w))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "import\n",
      "to\n",
      "by\n",
      "veri\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "new_text = \"It is important to by very pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
    "\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "for w in example_words:\n",
    "    print(sno.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset name :   hello.n.01\n",
      "\n",
      "Synset meaning :  an expression of greeting\n",
      "\n",
      "Synset example :  ['every morning they exchanged polite hellos']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet \n",
    "syn = wordnet.synsets('hello')[0] \n",
    "  \n",
    "print (\"Synset name :  \", syn.name()) \n",
    "  \n",
    "# Defining the word \n",
    "print (\"\\nSynset meaning : \", syn.definition()) \n",
    "  \n",
    "# list of phrases that use the word in context \n",
    "print (\"\\nSynset example : \", syn.examples()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset name :   hello.n.01\n",
      "\n",
      "Synset abstract term :   [Synset('greeting.n.01')]\n",
      "\n",
      "Synset specific term :   [Synset('calling_card.n.02'), Synset('good_afternoon.n.01'), Synset('good_morning.n.01'), Synset('hail.n.03'), Synset('hello.n.01'), Synset('pax.n.01'), Synset('reception.n.01'), Synset('regard.n.03'), Synset('salute.n.02'), Synset('salute.n.03'), Synset('welcome.n.02'), Synset('well-wishing.n.01')]\n",
      "\n",
      "Synset root hypernerm :   [Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet \n",
    "syn = wordnet.synsets('hello')[0] \n",
    "  \n",
    "print (\"Synset name :  \", syn.name()) \n",
    "  \n",
    "print (\"\\nSynset abstract term :  \", syn.hypernyms()) \n",
    "  \n",
    "print (\"\\nSynset specific term :  \",  \n",
    "       syn.hypernyms()[0].hyponyms()) \n",
    "  \n",
    "syn.root_hypernyms() \n",
    "  \n",
    "print (\"\\nSynset root hypernerm :  \", syn.root_hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better with POS tag: good\n",
      "better without POS tag: better\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better with POS tag:\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n",
    "print(\"better without POS tag:\", lemmatizer.lemmatize(\"better\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "pythoner\n",
      "pythoning\n",
      "pythoned\n",
      "pythonly\n",
      "dancing\n",
      "Working\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\",\"pythonly\",\"dancing\",\"Working\"]\n",
    "for w in example_words:\n",
    "    print(lemmatizer.lemmatize(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unhappy\n",
      "imprecise\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "example_words = [\"unhappy\",\"imprecise\"]\n",
    "for w in example_words:\n",
    "    print(lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "cise\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# From https://dictionary.cambridge.org/grammar/british-grammar/word-formation/prefixes\n",
    "english_prefixes = {\n",
    "\"anti\": \"\",    # e.g. anti-goverment, anti-racist, anti-war\n",
    "\"auto\": \"\",    # e.g. autobiography, automobile\n",
    "\"de\": \"\",      # e.g. de-classify, decontaminate, demotivate\n",
    "\"dis\": \"\",     # e.g. disagree, displeasure, disqualify\n",
    "\"down\": \"\",    # e.g. downgrade, downhearted\n",
    "\"extra\": \"\",   # e.g. extraordinary, extraterrestrial\n",
    "\"hyper\": \"\",   # e.g. hyperactive, hypertension\n",
    "\"il\": \"\",     # e.g. illegal\n",
    "\"im\": \"\",     # e.g. impossible\n",
    "\"in\": \"\",     # e.g. insecure\n",
    "\"ir\": \"\",     # e.g. irregular\n",
    "\"inter\": \"\",  # e.g. interactive, international\n",
    "\"mega\": \"\",   # e.g. megabyte, mega-deal, megaton\n",
    "\"mid\": \"\",    # e.g. midday, midnight, mid-October\n",
    "\"mis\": \"\",    # e.g. misaligned, mislead, misspelt\n",
    "\"non\": \"\",    # e.g. non-payment, non-smoking\n",
    "\"over\": \"\",  # e.g. overcook, overcharge, overrate\n",
    "\"out\": \"\",    # e.g. outdo, out-perform, outrun\n",
    "\"post\": \"\",   # e.g. post-election, post-warn\n",
    "\"pre\": \"\",    # e.g. prehistoric, pre-war\n",
    "\"pro\": \"\",    # e.g. pro-communist, pro-democracy\n",
    "\"re\": \"\",     # e.g. reconsider, redo, rewrite\n",
    "\"semi\": \"\",   # e.g. semicircle, semi-retired\n",
    "\"sub\": \"\",    # e.g. submarine, sub-Saharan\n",
    "\"super\": \"\",   # e.g. super-hero, supermodel\n",
    "\"tele\": \"\",    # e.g. television, telephathic\n",
    "\"trans\": \"\",   # e.g. transatlantic, transfer\n",
    "\"ultra\": \"\",   # e.g. ultra-compact, ultrasound\n",
    "\"un\": \"\",      # e.g. under-cook, underestimate\n",
    "\"up\": \"\",      # e.g. upgrade, uphill\n",
    "}\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "whitelist = list(wn.words()) + words.words()\n",
    "\n",
    "def stem_prefix(word, prefixes, roots):\n",
    "    original_word = word\n",
    "    for prefix in sorted(prefixes, key=len, reverse=True):\n",
    "        # Use subn to track the no. of substitution made.\n",
    "        # Allow dash in between prefix and root. \n",
    "        word, nsub = re.subn(\"{}[\\-]?\".format(prefix), \"\", word)\n",
    "        if nsub > 0 and word in roots:\n",
    "            return word\n",
    "    return original_word\n",
    "\n",
    "def porter_english_plus(word, prefixes=english_prefixes):\n",
    "    return porter.stem(stem_prefix(word, prefixes, whitelist))\n",
    "\n",
    "res1 = stem_prefix(\"unhappy\", english_prefixes, whitelist)\n",
    "print(res1)\n",
    "\n",
    "\n",
    "res2 = stem_prefix(\"imprecise\", english_prefixes, whitelist)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Levenshtein distance\n",
    "def lev(a, b):\n",
    "    if not a: return len(b)\n",
    "    if not b: return len(a)\n",
    "    return min(lev(a[1:], b[1:])+(a[0] != b[0]), lev(a[1:], b)+1, lev(a, b[1:])+1)\n",
    "\n",
    "print (lev('kitten', 'sitting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jaccard({'qval': ['hello', 'world'], 'as_set': ['world', 'hello'], 'external': True})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textdistance\n",
    "\n",
    "tokens_1 = \"hello world\".split()\n",
    "tokens_2 = \"world hello\".split()\n",
    "textdistance.Jaccard(tokens_1,tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(textdistance.hamming('text', 'test'))\n",
    "print(textdistance.hamming.normalized_similarity('text', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(textdistance.levenshtein('arrow', 'arow'))\n",
    "print(textdistance.levenshtein.normalized_similarity('arrow', 'arow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(textdistance.jaro_winkler(\"mes\", \"messi\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_1 = \"hello world\".split()\n",
    "tokens_2 = \"world hello\".split()\n",
    "textdistance.jaccard(tokens_1 , tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "tokens_1 = \"hello new world\".split()\n",
    "tokens_2 = \"hello world\".split()\n",
    "print(textdistance.jaccard(tokens_1 , tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tokens_1 = \"hello world\".split()\n",
    "tokens_2 = \"world hello\".split()\n",
    "print(textdistance.sorensen_dice(tokens_1 , tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "tokens_1 = \"hello new world\".split()\n",
    "tokens_2 = \"hello world\".split()\n",
    "print(textdistance.sorensen_dice(tokens_1 , tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.5\n",
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "string1, string2 = \"i am going home\", \"gone home\"\n",
    "print(textdistance.ratcliff_obershelp(string1, string2))\n",
    "\n",
    "string1, string2 = \"helloworld\", \"worldhello\"\n",
    "print(textdistance.ratcliff_obershelp(string1, string2))\n",
    "\n",
    "string1, string2 = \"test\", \"text\"\n",
    "print(textdistance.ratcliff_obershelp(string1, string2))\n",
    "\n",
    "string1, string2 = \"mes\", \"simes\"\n",
    "print(textdistance.ratcliff_obershelp(string1, string2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Sentence #1 (9 tokens):\r\n",
      "Ronaldo has moved from Real Madrid to Juventus.\r\n",
      "\r\n",
      "Tokens:\r\n",
      "[Text=Ronaldo CharacterOffsetBegin=0 CharacterOffsetEnd=7 PartOfSpeech=NNP Lemma=Ronaldo NamedEntityTag=PERSON]\r\n",
      "[Text=has CharacterOffsetBegin=8 CharacterOffsetEnd=11 PartOfSpeech=VBZ Lemma=have NamedEntityTag=O]\r\n",
      "[Text=moved CharacterOffsetBegin=12 CharacterOffsetEnd=17 PartOfSpeech=VBN Lemma=move NamedEntityTag=O]\r\n",
      "[Text=from CharacterOffsetBegin=18 CharacterOffsetEnd=22 PartOfSpeech=IN Lemma=from NamedEntityTag=O]\r\n",
      "[Text=Real CharacterOffsetBegin=23 CharacterOffsetEnd=27 PartOfSpeech=JJ Lemma=real NamedEntityTag=ORGANIZATION]\r\n",
      "[Text=Madrid CharacterOffsetBegin=28 CharacterOffsetEnd=34 PartOfSpeech=NNP Lemma=Madrid NamedEntityTag=ORGANIZATION]\r\n",
      "[Text=to CharacterOffsetBegin=35 CharacterOffsetEnd=37 PartOfSpeech=TO Lemma=to NamedEntityTag=O]\r\n",
      "[Text=Juventus CharacterOffsetBegin=38 CharacterOffsetEnd=46 PartOfSpeech=NNP Lemma=Juventus NamedEntityTag=ORGANIZATION]\r\n",
      "[Text=. CharacterOffsetBegin=46 CharacterOffsetEnd=47 PartOfSpeech=. Lemma=. NamedEntityTag=O]\r\n",
      "\r\n",
      "Extracted the following NER entity mentions:\r\n",
      "Ronaldo\tPERSON\r\n",
      "Real Madrid\tORGANIZATION\r\n",
      "Juventus\tORGANIZATION\r\n",
      "\r\n",
      "Sentence #2 (6 tokens):\r\n",
      "While messi still plays for Barcelona\r\n",
      "\r\n",
      "Tokens:\r\n",
      "[Text=While CharacterOffsetBegin=48 CharacterOffsetEnd=53 PartOfSpeech=IN Lemma=while NamedEntityTag=O]\r\n",
      "[Text=messi CharacterOffsetBegin=54 CharacterOffsetEnd=59 PartOfSpeech=NNS Lemma=messus NamedEntityTag=O]\r\n",
      "[Text=still CharacterOffsetBegin=60 CharacterOffsetEnd=65 PartOfSpeech=RB Lemma=still NamedEntityTag=O]\r\n",
      "[Text=plays CharacterOffsetBegin=66 CharacterOffsetEnd=71 PartOfSpeech=VBZ Lemma=play NamedEntityTag=O]\r\n",
      "[Text=for CharacterOffsetBegin=72 CharacterOffsetEnd=75 PartOfSpeech=IN Lemma=for NamedEntityTag=O]\r\n",
      "[Text=Barcelona CharacterOffsetBegin=76 CharacterOffsetEnd=85 PartOfSpeech=NNP Lemma=Barcelona NamedEntityTag=ORGANIZATION]\r\n",
      "\r\n",
      "Extracted the following NER entity mentions:\r\n",
      "Barcelona\tORGANIZATION\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp_wrapper = StanfordCoreNLP('http://localhost:54567')\n",
    "doc = \"Ronaldo has moved from Real Madrid to Juventus. While messi still plays for Barcelona\"\n",
    "annot_doc = nlp_wrapper.annotate(doc,\n",
    "    properties={\n",
    "        'annotators': 'ner, pos',\n",
    "        'outputFormat': 'text',\n",
    "        'timeout': 1000,\n",
    "    })\n",
    "print (annot_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Sentence #1 (9 tokens):\r\n",
      "Ronaldo has moved from Real Madrid to Juventus.\r\n",
      "\r\n",
      "Tokens:\r\n",
      "[Text=Ronaldo CharacterOffsetBegin=0 CharacterOffsetEnd=7 PartOfSpeech=NNP]\r\n",
      "[Text=has CharacterOffsetBegin=8 CharacterOffsetEnd=11 PartOfSpeech=VBZ]\r\n",
      "[Text=moved CharacterOffsetBegin=12 CharacterOffsetEnd=17 PartOfSpeech=VBN]\r\n",
      "[Text=from CharacterOffsetBegin=18 CharacterOffsetEnd=22 PartOfSpeech=IN]\r\n",
      "[Text=Real CharacterOffsetBegin=23 CharacterOffsetEnd=27 PartOfSpeech=JJ]\r\n",
      "[Text=Madrid CharacterOffsetBegin=28 CharacterOffsetEnd=34 PartOfSpeech=NNP]\r\n",
      "[Text=to CharacterOffsetBegin=35 CharacterOffsetEnd=37 PartOfSpeech=TO]\r\n",
      "[Text=Juventus CharacterOffsetBegin=38 CharacterOffsetEnd=46 PartOfSpeech=NNP]\r\n",
      "[Text=. CharacterOffsetBegin=46 CharacterOffsetEnd=47 PartOfSpeech=.]\r\n",
      "\r\n",
      "Constituency parse: \r\n",
      "(ROOT\r\n",
      "  (S\r\n",
      "    (NP (NNP Ronaldo))\r\n",
      "    (VP (VBZ has)\r\n",
      "      (VP (VBN moved)\r\n",
      "        (PP (IN from)\r\n",
      "          (NP (JJ Real) (NNP Madrid)))\r\n",
      "        (PP (TO to)\r\n",
      "          (NP (NNP Juventus)))))\r\n",
      "    (. .)))\r\n",
      "\r\n",
      "\r\n",
      "Dependency Parse (enhanced plus plus dependencies):\r\n",
      "root(ROOT-0, moved-3)\n",
      "nsubj(moved-3, Ronaldo-1)\n",
      "aux(moved-3, has-2)\n",
      "case(Madrid-6, from-4)\n",
      "amod(Madrid-6, Real-5)\n",
      "nmod:from(moved-3, Madrid-6)\n",
      "case(Juventus-8, to-7)\n",
      "nmod:to(moved-3, Juventus-8)\n",
      "punct(moved-3, .-9)\n",
      "\r\n",
      "Sentence #2 (6 tokens):\r\n",
      "While messi still plays for Barcelona\r\n",
      "\r\n",
      "Tokens:\r\n",
      "[Text=While CharacterOffsetBegin=48 CharacterOffsetEnd=53 PartOfSpeech=IN]\r\n",
      "[Text=messi CharacterOffsetBegin=54 CharacterOffsetEnd=59 PartOfSpeech=NNS]\r\n",
      "[Text=still CharacterOffsetBegin=60 CharacterOffsetEnd=65 PartOfSpeech=RB]\r\n",
      "[Text=plays CharacterOffsetBegin=66 CharacterOffsetEnd=71 PartOfSpeech=VBZ]\r\n",
      "[Text=for CharacterOffsetBegin=72 CharacterOffsetEnd=75 PartOfSpeech=IN]\r\n",
      "[Text=Barcelona CharacterOffsetBegin=76 CharacterOffsetEnd=85 PartOfSpeech=NNP]\r\n",
      "\r\n",
      "Constituency parse: \r\n",
      "(ROOT\r\n",
      "  (SBAR (IN While)\r\n",
      "    (S\r\n",
      "      (NP (NNS messi))\r\n",
      "      (ADVP (RB still))\r\n",
      "      (VP (VBZ plays)\r\n",
      "        (PP (IN for)\r\n",
      "          (NP (NNP Barcelona)))))))\r\n",
      "\r\n",
      "\r\n",
      "Dependency Parse (enhanced plus plus dependencies):\r\n",
      "root(ROOT-0, plays-4)\n",
      "mark(plays-4, While-1)\n",
      "nsubj(plays-4, messi-2)\n",
      "advmod(plays-4, still-3)\n",
      "case(Barcelona-6, for-5)\n",
      "nmod:for(plays-4, Barcelona-6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annot_doc = nlp_wrapper.annotate(doc,\n",
    "    properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,depparse,parse',\n",
    "        'outputFormat': 'text',\n",
    "        'timeout': 1000,\n",
    "    })\n",
    "print (annot_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\r\n",
      "  (S\r\n",
      "    (NP (NNP Ronaldo))\r\n",
      "    (VP (VBZ has)\r\n",
      "      (VP (VBN moved)\r\n",
      "        (PP (IN from)\r\n",
      "          (NP (JJ Real) (NNP Madrid)))\r\n",
      "        (PP (TO to)\r\n",
      "          (NP (NNP Juventus)))))\r\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "annot_doc = nlp_wrapper.annotate(doc,\n",
    "    properties={\n",
    "        'annotators': 'tokenize,ssplit,pos,depparse,parse',\n",
    "        'outputFormat': 'json',\n",
    "        'timeout': 1000,\n",
    "    })\n",
    "print((annot_doc)['sentences'][0]['parse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT\r\n",
      "  (SBAR (IN While)\r\n",
      "    (S\r\n",
      "      (NP (NNS messi))\r\n",
      "      (ADVP (RB still))\r\n",
      "      (VP (VBZ plays)\r\n",
      "        (PP (IN for)\r\n",
      "          (NP (NNP Barcelona)))))))\n"
     ]
    }
   ],
   "source": [
    "print((annot_doc)['sentences'][1]['parse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 'I love you .': 3 Positive\n",
      "1: 'I hate him .': 1 Negative\n",
      "2: 'You are nice .': 3 Positive\n",
      "3: 'He is dumb': 1 Negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = nlp_wrapper.annotate(\"I love you. I hate him. You are nice. He is dumb\",\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json'\n",
    "                   })\n",
    "for s in res[\"sentences\"]:\n",
    "    print (\"%d: '%s': %s %s\" % (\n",
    "        s[\"index\"],\n",
    "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "        s[\"sentimentValue\"], s[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"corefs\": {\n",
      "        \"3\": [\n",
      "            {\n",
      "                \"animacy\": \"ANIMATE\",\n",
      "                \"endIndex\": 3,\n",
      "                \"gender\": \"MALE\",\n",
      "                \"headIndex\": 2,\n",
      "                \"id\": 0,\n",
      "                \"isRepresentativeMention\": true,\n",
      "                \"number\": \"SINGULAR\",\n",
      "                \"position\": [\n",
      "                    1,\n",
      "                    1\n",
      "                ],\n",
      "                \"sentNum\": 1,\n",
      "                \"startIndex\": 1,\n",
      "                \"text\": \"Barack Obama\",\n",
      "                \"type\": \"PROPER\"\n",
      "            },\n",
      "            {\n",
      "                \"animacy\": \"ANIMATE\",\n",
      "                \"endIndex\": 2,\n",
      "                \"gender\": \"MALE\",\n",
      "                \"headIndex\": 1,\n",
      "                \"id\": 3,\n",
      "                \"isRepresentativeMention\": false,\n",
      "                \"number\": \"SINGULAR\",\n",
      "                \"position\": [\n",
      "                    2,\n",
      "                    2\n",
      "                ],\n",
      "                \"sentNum\": 2,\n",
      "                \"startIndex\": 1,\n",
      "                \"text\": \"He\",\n",
      "                \"type\": \"PRONOMINAL\"\n",
      "            },\n",
      "            {\n",
      "                \"animacy\": \"ANIMATE\",\n",
      "                \"endIndex\": 2,\n",
      "                \"gender\": \"MALE\",\n",
      "                \"headIndex\": 1,\n",
      "                \"id\": 4,\n",
      "                \"isRepresentativeMention\": false,\n",
      "                \"number\": \"SINGULAR\",\n",
      "                \"position\": [\n",
      "                    3,\n",
      "                    1\n",
      "                ],\n",
      "                \"sentNum\": 3,\n",
      "                \"startIndex\": 1,\n",
      "                \"text\": \"Obama\",\n",
      "                \"type\": \"PROPER\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"sentences\": [\n",
      "        {\n",
      "            \"basicDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"born\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"compound\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"Barack\",\n",
      "                    \"governor\": 2,\n",
      "                    \"governorGloss\": \"Obama\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubjpass\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"Obama\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"auxpass\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"was\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"case\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \"in\",\n",
      "                    \"governor\": 6,\n",
      "                    \"governorGloss\": \"Hawaii\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nmod\",\n",
      "                    \"dependent\": 6,\n",
      "                    \"dependentGloss\": \"Hawaii\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 7,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                }\n",
      "            ],\n",
      "            \"enhancedDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"born\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"compound\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"Barack\",\n",
      "                    \"governor\": 2,\n",
      "                    \"governorGloss\": \"Obama\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubjpass\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"Obama\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"auxpass\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"was\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"case\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \"in\",\n",
      "                    \"governor\": 6,\n",
      "                    \"governorGloss\": \"Hawaii\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nmod:in\",\n",
      "                    \"dependent\": 6,\n",
      "                    \"dependentGloss\": \"Hawaii\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 7,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                }\n",
      "            ],\n",
      "            \"enhancedPlusPlusDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"born\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"compound\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"Barack\",\n",
      "                    \"governor\": 2,\n",
      "                    \"governorGloss\": \"Obama\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubjpass\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"Obama\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"auxpass\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"was\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"case\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \"in\",\n",
      "                    \"governor\": 6,\n",
      "                    \"governorGloss\": \"Hawaii\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nmod:in\",\n",
      "                    \"dependent\": 6,\n",
      "                    \"dependentGloss\": \"Hawaii\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 7,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"born\"\n",
      "                }\n",
      "            ],\n",
      "            \"entitymentions\": [\n",
      "                {\n",
      "                    \"characterOffsetBegin\": 0,\n",
      "                    \"characterOffsetEnd\": 12,\n",
      "                    \"docTokenBegin\": 0,\n",
      "                    \"docTokenEnd\": 2,\n",
      "                    \"ner\": \"PERSON\",\n",
      "                    \"text\": \"Barack Obama\",\n",
      "                    \"tokenBegin\": 0,\n",
      "                    \"tokenEnd\": 2\n",
      "                },\n",
      "                {\n",
      "                    \"characterOffsetBegin\": 25,\n",
      "                    \"characterOffsetEnd\": 31,\n",
      "                    \"docTokenBegin\": 5,\n",
      "                    \"docTokenEnd\": 6,\n",
      "                    \"ner\": \"STATE_OR_PROVINCE\",\n",
      "                    \"text\": \"Hawaii\",\n",
      "                    \"tokenBegin\": 5,\n",
      "                    \"tokenEnd\": 6\n",
      "                }\n",
      "            ],\n",
      "            \"index\": 0,\n",
      "            \"tokens\": [\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \"\",\n",
      "                    \"characterOffsetBegin\": 0,\n",
      "                    \"characterOffsetEnd\": 6,\n",
      "                    \"index\": 1,\n",
      "                    \"lemma\": \"Barack\",\n",
      "                    \"ner\": \"PERSON\",\n",
      "                    \"originalText\": \"Barack\",\n",
      "                    \"pos\": \"NNP\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"Barack\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 7,\n",
      "                    \"characterOffsetEnd\": 12,\n",
      "                    \"index\": 2,\n",
      "                    \"lemma\": \"Obama\",\n",
      "                    \"ner\": \"PERSON\",\n",
      "                    \"originalText\": \"Obama\",\n",
      "                    \"pos\": \"NNP\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"Obama\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 13,\n",
      "                    \"characterOffsetEnd\": 16,\n",
      "                    \"index\": 3,\n",
      "                    \"lemma\": \"be\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"was\",\n",
      "                    \"pos\": \"VBD\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"was\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 17,\n",
      "                    \"characterOffsetEnd\": 21,\n",
      "                    \"index\": 4,\n",
      "                    \"lemma\": \"bear\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"born\",\n",
      "                    \"pos\": \"VBN\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"born\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 22,\n",
      "                    \"characterOffsetEnd\": 24,\n",
      "                    \"index\": 5,\n",
      "                    \"lemma\": \"in\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"in\",\n",
      "                    \"pos\": \"IN\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"in\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \"\",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 25,\n",
      "                    \"characterOffsetEnd\": 31,\n",
      "                    \"index\": 6,\n",
      "                    \"lemma\": \"Hawaii\",\n",
      "                    \"ner\": \"STATE_OR_PROVINCE\",\n",
      "                    \"originalText\": \"Hawaii\",\n",
      "                    \"pos\": \"NNP\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"Hawaii\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \"  \",\n",
      "                    \"before\": \"\",\n",
      "                    \"characterOffsetBegin\": 31,\n",
      "                    \"characterOffsetEnd\": 32,\n",
      "                    \"index\": 7,\n",
      "                    \"lemma\": \".\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \".\",\n",
      "                    \"pos\": \".\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \".\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"basicDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"president\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubj\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"He\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"cop\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"is\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"det\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"the\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                }\n",
      "            ],\n",
      "            \"enhancedDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"president\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubj\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"He\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"cop\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"is\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"det\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"the\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                }\n",
      "            ],\n",
      "            \"enhancedPlusPlusDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"president\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubj\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"He\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"cop\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"is\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"det\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"the\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 4,\n",
      "                    \"governorGloss\": \"president\"\n",
      "                }\n",
      "            ],\n",
      "            \"entitymentions\": [\n",
      "                {\n",
      "                    \"characterOffsetBegin\": 44,\n",
      "                    \"characterOffsetEnd\": 53,\n",
      "                    \"docTokenBegin\": 10,\n",
      "                    \"docTokenEnd\": 11,\n",
      "                    \"ner\": \"TITLE\",\n",
      "                    \"text\": \"president\",\n",
      "                    \"tokenBegin\": 3,\n",
      "                    \"tokenEnd\": 4\n",
      "                },\n",
      "                {\n",
      "                    \"characterOffsetBegin\": 34,\n",
      "                    \"characterOffsetEnd\": 36,\n",
      "                    \"docTokenBegin\": 7,\n",
      "                    \"docTokenEnd\": 8,\n",
      "                    \"ner\": \"PERSON\",\n",
      "                    \"text\": \"He\",\n",
      "                    \"tokenBegin\": 0,\n",
      "                    \"tokenEnd\": 1\n",
      "                }\n",
      "            ],\n",
      "            \"index\": 1,\n",
      "            \"tokens\": [\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \"  \",\n",
      "                    \"characterOffsetBegin\": 34,\n",
      "                    \"characterOffsetEnd\": 36,\n",
      "                    \"index\": 1,\n",
      "                    \"lemma\": \"he\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"He\",\n",
      "                    \"pos\": \"PRP\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"He\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 37,\n",
      "                    \"characterOffsetEnd\": 39,\n",
      "                    \"index\": 2,\n",
      "                    \"lemma\": \"be\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"is\",\n",
      "                    \"pos\": \"VBZ\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"is\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 40,\n",
      "                    \"characterOffsetEnd\": 43,\n",
      "                    \"index\": 3,\n",
      "                    \"lemma\": \"the\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"the\",\n",
      "                    \"pos\": \"DT\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"the\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \"\",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 44,\n",
      "                    \"characterOffsetEnd\": 53,\n",
      "                    \"index\": 4,\n",
      "                    \"lemma\": \"president\",\n",
      "                    \"ner\": \"TITLE\",\n",
      "                    \"originalText\": \"president\",\n",
      "                    \"pos\": \"NN\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"president\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \"\",\n",
      "                    \"characterOffsetBegin\": 53,\n",
      "                    \"characterOffsetEnd\": 54,\n",
      "                    \"index\": 5,\n",
      "                    \"lemma\": \".\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \".\",\n",
      "                    \"pos\": \".\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \".\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"basicDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"elected\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubjpass\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"Obama\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"auxpass\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"was\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"case\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"in\",\n",
      "                    \"governor\": 5,\n",
      "                    \"governorGloss\": \"2008\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nmod\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \"2008\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 6,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                }\n",
      "            ],\n",
      "            \"enhancedDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"elected\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubjpass\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"Obama\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"auxpass\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"was\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"case\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"in\",\n",
      "                    \"governor\": 5,\n",
      "                    \"governorGloss\": \"2008\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nmod:in\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \"2008\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 6,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                }\n",
      "            ],\n",
      "            \"enhancedPlusPlusDependencies\": [\n",
      "                {\n",
      "                    \"dep\": \"ROOT\",\n",
      "                    \"dependent\": 3,\n",
      "                    \"dependentGloss\": \"elected\",\n",
      "                    \"governor\": 0,\n",
      "                    \"governorGloss\": \"ROOT\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nsubjpass\",\n",
      "                    \"dependent\": 1,\n",
      "                    \"dependentGloss\": \"Obama\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"auxpass\",\n",
      "                    \"dependent\": 2,\n",
      "                    \"dependentGloss\": \"was\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"case\",\n",
      "                    \"dependent\": 4,\n",
      "                    \"dependentGloss\": \"in\",\n",
      "                    \"governor\": 5,\n",
      "                    \"governorGloss\": \"2008\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"nmod:in\",\n",
      "                    \"dependent\": 5,\n",
      "                    \"dependentGloss\": \"2008\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"dep\": \"punct\",\n",
      "                    \"dependent\": 6,\n",
      "                    \"dependentGloss\": \".\",\n",
      "                    \"governor\": 3,\n",
      "                    \"governorGloss\": \"elected\"\n",
      "                }\n",
      "            ],\n",
      "            \"entitymentions\": [\n",
      "                {\n",
      "                    \"characterOffsetBegin\": 55,\n",
      "                    \"characterOffsetEnd\": 60,\n",
      "                    \"docTokenBegin\": 12,\n",
      "                    \"docTokenEnd\": 13,\n",
      "                    \"ner\": \"PERSON\",\n",
      "                    \"text\": \"Obama\",\n",
      "                    \"tokenBegin\": 0,\n",
      "                    \"tokenEnd\": 1\n",
      "                },\n",
      "                {\n",
      "                    \"characterOffsetBegin\": 76,\n",
      "                    \"characterOffsetEnd\": 80,\n",
      "                    \"docTokenBegin\": 16,\n",
      "                    \"docTokenEnd\": 17,\n",
      "                    \"ner\": \"DATE\",\n",
      "                    \"normalizedNER\": \"2008\",\n",
      "                    \"text\": \"2008\",\n",
      "                    \"timex\": {\n",
      "                        \"tid\": \"t1\",\n",
      "                        \"type\": \"DATE\",\n",
      "                        \"value\": \"2008\"\n",
      "                    },\n",
      "                    \"tokenBegin\": 4,\n",
      "                    \"tokenEnd\": 5\n",
      "                }\n",
      "            ],\n",
      "            \"index\": 2,\n",
      "            \"tokens\": [\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 55,\n",
      "                    \"characterOffsetEnd\": 60,\n",
      "                    \"index\": 1,\n",
      "                    \"lemma\": \"Obama\",\n",
      "                    \"ner\": \"PERSON\",\n",
      "                    \"originalText\": \"Obama\",\n",
      "                    \"pos\": \"NNP\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"Obama\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 61,\n",
      "                    \"characterOffsetEnd\": 64,\n",
      "                    \"index\": 2,\n",
      "                    \"lemma\": \"be\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"was\",\n",
      "                    \"pos\": \"VBD\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"was\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 65,\n",
      "                    \"characterOffsetEnd\": 72,\n",
      "                    \"index\": 3,\n",
      "                    \"lemma\": \"elect\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"elected\",\n",
      "                    \"pos\": \"VBN\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"elected\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \" \",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 73,\n",
      "                    \"characterOffsetEnd\": 75,\n",
      "                    \"index\": 4,\n",
      "                    \"lemma\": \"in\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \"in\",\n",
      "                    \"pos\": \"IN\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \"in\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \"\",\n",
      "                    \"before\": \" \",\n",
      "                    \"characterOffsetBegin\": 76,\n",
      "                    \"characterOffsetEnd\": 80,\n",
      "                    \"index\": 5,\n",
      "                    \"lemma\": \"2008\",\n",
      "                    \"ner\": \"DATE\",\n",
      "                    \"normalizedNER\": \"2008\",\n",
      "                    \"originalText\": \"2008\",\n",
      "                    \"pos\": \"CD\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"timex\": {\n",
      "                        \"tid\": \"t1\",\n",
      "                        \"type\": \"DATE\",\n",
      "                        \"value\": \"2008\"\n",
      "                    },\n",
      "                    \"word\": \"2008\"\n",
      "                },\n",
      "                {\n",
      "                    \"after\": \"\",\n",
      "                    \"before\": \"\",\n",
      "                    \"characterOffsetBegin\": 80,\n",
      "                    \"characterOffsetEnd\": 81,\n",
      "                    \"index\": 6,\n",
      "                    \"lemma\": \".\",\n",
      "                    \"ner\": \"O\",\n",
      "                    \"originalText\": \".\",\n",
      "                    \"pos\": \".\",\n",
      "                    \"speaker\": \"PER0\",\n",
      "                    \"word\": \".\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp_wrapper = StanfordCoreNLP('http://localhost:54567')\n",
    "text = 'Barack Obama was born in Hawaii.  He is the president. Obama was elected in 2008.'\n",
    "props = {'annotators': 'coref', 'pipelineLanguage': 'en'}\n",
    "result = json.loads(nlp_wrapper.annotate(text, properties=props))\n",
    "\n",
    "print(json.dumps(result, indent = 4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_coref_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-136a8a5e2e28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_coref_lg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_coref_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_coref_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
